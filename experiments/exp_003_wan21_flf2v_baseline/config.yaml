experiment_name: exp_003_wan21_flf2v_baseline

model:
  # Set this to a valid Diffusers FLF2V-capable repo id in your environment.
  repo_id: "Wan-AI/Wan2.1-FLF2V-14B-720P"
  torch_dtype: bfloat16          # float16 | bfloat16 | float32
  use_safetensors: true

inputs:
  prompt: "A smooth cinematic transition from the first frame scene into the last frame scene."
  negative_prompt: "flicker, jitter, artifacts, blur"
  start_frame: data/processed/vc_bench_samples/start_frame.png
  end_frame: data/processed/vc_bench_samples/end_frame.png

inference:
  num_frames: 81
  num_inference_steps: 30
  guidance_scale: 5.0
  height: 720
  width: 1280

runtime:
  seed: 42
  device: auto                   # auto | cuda | cpu
  enable_model_cpu_offload: true
  dry_run: true                  # true = validate setup only, no model call

outputs:
  root_dir: outputs/videos
  save_frames: true
