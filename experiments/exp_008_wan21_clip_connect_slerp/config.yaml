# Experiment 008 â€” Wan 2.1 T2V 1.3B clip-to-clip with SLERP guidance.
# Single-pass iteration experiment (fork of exp_007).
# Middle latent frames are initialised via SLERP interpolation between the
# boundary frames of the two anchor clips instead of pure Gaussian noise.

experiment_name: exp_008_wan21_clip_connect_slerp

model:
  repo_id: "Wan-AI/Wan2.1-T2V-1.3B-Diffusers"
  transformer_dtype: bfloat16
  text_encoder_dtype: bfloat16
  vae_dtype: float32

inputs:
  pair_id: "pair_A_same"
  start_clip: data/processed/vc-bench-flf/first_last_clips_24/Actions_Activities_action_action_1581362_2562x1440_b27b9c451a/first.mp4
  end_clip:   data/processed/vc-bench-flf/first_last_clips_24/Actions_Activities_action_action_1581362_2562x1440_b27b9c451a/last.mp4

  prompt: "continuous motion video"

  negative_prompt: >
    bright tones, overexposed, static, blurred details, subtitles, style,
    works, paintings, images, static, overall gray, worst quality, low quality,
    JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn
    hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused
    fingers, still picture, messy background, three legs, many people in the
    background, walking backwards

inference:
  num_frames: 73
  anchor_frames: 24
  height: 480
  width: 848
  num_inference_steps: 15
  guidance_scale: 1.0
  enable_vae_tiling: true
  enable_slerp_guidance: true

runtime:
  seed: 42
  device: cuda
  dry_run: false
  enable_model_cpu_offload: false

outputs:
  root_dir: outputs/videos
  fps: 16
