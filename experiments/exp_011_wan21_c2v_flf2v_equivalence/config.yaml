model:
  repo_id: "Wan-AI/Wan2.1-FLF2V-14B-720P-Diffusers"

inputs:
  # Identical to exp_009 — same PNG frames, same sample.
  first_frame: "data/processed/vc-bench-flf/first_last_frames/Actions_Activities_action_action_1581362_2562x1440_b27b9c451a/first.png"
  last_frame:  "data/processed/vc-bench-flf/first_last_frames/Actions_Activities_action_action_1581362_2562x1440_b27b9c451a/last.png"
  anchor_frames: 1   # single-frame anchors → reproduces FLF2V exactly
  prompt: "Opening shot: the scene starts with the composition and subject style of
    the first frame. Camera motion: a smooth, cinematic dolly movement with stable
    temporal continuity, natural parallax, and coherent subject motion through the
    transition. Reveal/payoff: the scene gradually resolves into the composition,
    subject arrangement, and mood of the last frame. Keep realistic lighting, clean
    details, consistent geometry, and filmic color grading without abrupt jumps."
  negative_prompt: >
    bright tones, overexposed, static, blurred details, subtitles, style,
    works, paintings, images, static, overall gray, worst quality, low quality,
    JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn
    hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused
    fingers, still picture, messy background, three legs, many people in the
    background, walking backwards

inference:
  max_area: 399360   # 720 * 1280 — identical to exp_009
  # num_frames = 1 (start) + 23 (generated middle) + 1 (end) = 25
  # (25 - 1) % 4 == 0 ✓  |  anchor_frames * 2 < num_frames → 2 < 25 ✓
  num_frames: 25
  num_inference_steps: 15
  guidance_scale: 5.5

runtime:
  seed: 42
  device: cuda
  dtype: bfloat16
  cpu_offload: true

outputs:
  dir: "outputs/videos/exp_011_wan21_c2v_flf2v_equivalence"
  fps: 16
